import os
import sys
import shutil
from pathlib import Path
import time  # ƒêo gi·ªù
import warnings # T·∫Øt c·∫£nh b√°o
import logging # T·∫Øt log h·ªá th·ªëng
import contextlib # D√πng ƒë·ªÉ ch·∫∑n output c·ª©ng ƒë·∫ßu

# --- 0. C·∫§U H√åNH T·∫ÆT C·∫¢NH B√ÅO (L√†m s·∫°ch m√†n h√¨nh) ---
# T·∫Øt warnings python
warnings.simplefilter("ignore")
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3" 
os.environ["TORCH_FORCE_WEIGHTS_ONLY_LOAD"] = "0"

# T·∫Øt logging c·ªßa c√°c th∆∞ vi·ªán con (C·∫•u h√¨nh t·∫≠n g·ªëc)
logging.getLogger().setLevel(logging.ERROR) # T·∫Øt to√†n b·ªô Info log h·ªá th·ªëng
for logger_name in ["whisperx", "lightning", "pytorch_lightning", "pyannote", "speechbrain"]:
    logging.getLogger(logger_name).setLevel(logging.ERROR)

# H√†m ch·∫∑n output th·ª´a (nh·ªØng d√≤ng ch·ªØ ƒë·ªè kh√¥ng th·ªÉ t·∫Øt b·∫±ng logging)
@contextlib.contextmanager
def suppress_output():
    with open(os.devnull, "w") as devnull:
        old_stderr = sys.stderr
        old_stdout = sys.stdout
        sys.stderr = devnull
        sys.stdout = devnull
        try:  
            yield
        finally:
            sys.stderr = old_stderr
            sys.stdout = old_stdout

# 1. Setup FFmpeg
BASE_DIR = Path(__file__).resolve().parent
ffmpeg_bin_path = BASE_DIR / "resourse4whisper" / "ffmpeg-8.0.1-essentials_build" / "bin"
os.environ["PATH"] = str(ffmpeg_bin_path) + os.pathsep + os.environ["PATH"]

ffmpeg_exe = shutil.which("ffmpeg")
if ffmpeg_exe:
    print(f"‚úÖ FFmpeg Ready.") 
else:
    print(f"‚ùå Error: Kh√¥ng t√¨m th·∫•y FFmpeg t·∫°i {ffmpeg_bin_path}")

import torch
import whisperx
import gc
from typing import Optional

# --- 2. FIX L·ªñI PYTORCH 2.6 ---
def setup_torch():
    _original_torch_load = torch.load
    def new_torch_load(*args, **kwargs):
        kwargs['weights_only'] = False 
        return _original_torch_load(*args, **kwargs)
    torch.load = new_torch_load
    os.environ["TORCH_FORCE_WEIGHTS_ONLY_LOAD"] = "0"

setup_torch()

def format_timestamp(seconds: float) -> str:
    x = int(seconds)
    msec = int((seconds - x) * 1000)
    hours = x // 3600
    minutes = (x % 3600) // 60
    seconds = x % 60
    return f"{hours:02d}:{minutes:02d}:{seconds:02d},{msec:03d}"

# --- 3. CLASS CH√çNH ---
class WhisperTranscriber:
    def __init__(self, model_size="small", device=None, compute_type="int8", batch_size=16):
        self.device = device if device else ("cuda" if torch.cuda.is_available() else "cpu")
        self.batch_size = batch_size
        print(f"üîπ Model: {model_size} | Device: {self.device} | Type: {compute_type}")
        try:
            # Th·ª≠ load "im l·∫∑ng" tr∆∞·ªõc
            with suppress_output():
                self.model = whisperx.load_model(
                    model_size,                     # large-v2, medium, small 
                    self.device,                    # "cuda", "cpu"
                    compute_type=compute_type       # "float16" - m·∫∑c ƒë·ªãnh, "int8": cho GPU y·∫øu, "float32": b·∫Øt bu·ªôc tr√™n CPU
                    # language = "vi", "en", None   # n·∫øu bi·∫øt ch·∫Øc -> ti·∫øt ki·ªám th·ªùi gian load
                    '''
                    # TƒÉng ƒë·ªô ch√≠nh x√°c & Cung c·∫•p ng·ªØ c·∫£nh
                    asr_options={
                        "beam_size": 10,    # T√¨m ki·∫øm k·ªπ h∆°n (m·∫∑c ƒë·ªãnh 5)
                        "initial_prompt": "H·ªôi tho·∫°i ti·∫øng Vi·ªát, ch·ªß ƒë·ªÅ c√¥ng ngh·ªá th√¥ng tin, l·∫≠p tr√¨nh Python." 
                    },
                    
                    # Tinh ch·ªânh c·∫Øt gi·ªçng n√≥i (n·∫øu th·∫•y b·ªã m·∫•t ch·ªØ ƒë·∫ßu c√¢u th√¨ gi·∫£m vad_onset)

                    B·∫°n n√™n th√™m m·ªôt h√†m ti·ªÅn x·ª≠ l√Ω (pre-process) d√πng FFmpeg ƒë·ªÉ t·∫°o ra file t·∫°m th·ªùi ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a, sau ƒë√≥ m·ªõi ƒë∆∞a v√†o Whisper.
                    
                    vad_options={
                        "vad_onset": 0.4,   # Nh·∫°y h∆°n m·∫∑c ƒë·ªãnh m·ªôt ch√∫t
                        "vad_offset": 0.35
                    }
                    X√°c su·∫•t (Prob)
                      1.0 |          ________ ƒë·ªânh cao tr√†o (n√≥i to)
                          |         /        \
                      0.8 |        /          \
                          |       /            \
                      0.5 |------/--------------\------------------ (M·∫∑c ƒë·ªãnh Onset) -> B·∫Øt ƒë·∫ßu c·∫Øt T·∫†I ƒê√ÇY
                      0.4 |-----/----------------\----------------- (Onset T√πy ch·ªânh) -> B·∫Øt ƒë·∫ßu c·∫Øt S·ªöM H∆†N (L·∫•y ƒë∆∞·ª£c ch·ªØ ƒë·∫ßu)
                          |    /                  \
                      0.3 |---/--------------------\--------------- (Offset) -> K·∫øt th√∫c c·∫Øt (Cho ph√©p gi·ªçng nh·ªè d·∫ßn)
                          |  /                      \
                      0.0 |_/                        \____________
                    Time:  (Ti·∫øng th·ªü/nh·ªè)   (N√≥i r√µ)      (N√≥i nh·ªè/k·∫øt c√¢u)
                    '''
                    )
        except Exception: 
            # Th·ª≠ load l·∫°i "c√¥ng khai" ƒë·ªÉ hi·ªán l·ªói ho·∫∑c thanh download
            self.model = whisperx.load_model(model_size, self.device, compute_type=compute_type)
            
        print(f"‚úÖ Model ({model_size}) Ready.")

    def transcribe_file(self, audio_path: str, language: Optional[str] = None):
        if not os.path.exists(audio_path):
            print(f"‚ùå File not found: {audio_path}")
            return False

        print(f"üéß Processing: {os.path.basename(audio_path)}")
        
        # B1. Transcribe
        audio = whisperx.load_audio(audio_path)
        result = self.model.transcribe(audio, batch_size=self.batch_size, language=language)
        # self.model.transcribe(audio, ...)
        # task="translate",       # D·ªãch th·∫≥ng sang ti·∫øng Anh (n·∫øu c·∫ßn)
        # num_workers=4,          # D√πng 4 lu·ªìng CPU ƒë·ªÉ chu·∫©n b·ªã d·ªØ li·ªáu nhanh h∆°n
        # print_progress=False    # T·∫Øt thanh loading bar m·∫∑c ƒë·ªãnh c·ªßa th∆∞ vi·ªán

        # B2. Align
        try:
            model_a, metadata = whisperx.load_align_model(language_code=result["language"], device=self.device)
            result = whisperx.align(result["segments"], model_a, metadata, audio, self.device, return_char_alignments=False)
            del model_a; del metadata; gc.collect(); torch.cuda.empty_cache()
        except Exception:
            return False

        # B3. Save
        self._save_srt(result["segments"], audio_path, is_word_level=False)
        self._save_srt(result["segments"], audio_path, is_word_level=True)
        return True

    def _save_srt(self, segments, audio_path, is_word_level=False):
        suffix = "_word.srt" if is_word_level else ".srt"
        output_file = model_size + "_" + audio_path.rsplit('.', 1)[0] + suffix
        with open(output_file, "w", encoding="utf-8") as f:
            counter = 1
            if is_word_level:
                for seg in segments:
                    if 'words' not in seg: continue
                    for w in seg['words']:
                        if 'start' in w and 'end' in w:
                            f.write(f"{counter}\n{format_timestamp(w['start'])} --> {format_timestamp(w['end'])}\n{w['word'].strip()}\n\n")
                            counter += 1
            else:
                for seg in segments:
                    f.write(f"{counter}\n{format_timestamp(seg['start'])} --> {format_timestamp(seg['end'])}\n{seg['text'].strip()}\n\n")
                    counter += 1

    def close(self):
        del self.model; gc.collect(); torch.cuda.empty_cache()

# --- 4. H√ÄM LOG ---
def write_log(file_name, size_mb, duration, model_size, compute_type, batch_size):
    with open("Log_Time4Mp3_2_SRT.txt", "a", encoding="utf-8") as f:
        f.write(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] File: {file_name[file_name.find('.'):]} | Size: {size_mb:.2f} MB | Time: {duration:.2f}s | Model: {model_size} | Compute_type: {compute_type} | Batch_size: {batch_size}\n")
    print(f"üìù Log saved: history_log.txt | Time: {duration:.2f}s")

# --- 5. CH·∫†Y ---
if __name__ == "__main__":
    MY_AUDIO = r"How to Talk to Anyone with Confidence  English Podcast For Learning English  English Leap Podcast.mp4"
    
    compute_type="int8";  
    batch_size=16;  
    model_size="small";

    start = time.time()
    app = WhisperTranscriber(compute_type=compute_type, batch_size=batch_size, model_size=model_size)
    #    compute_type = "int8" ; batch_size = 16 (ho·∫∑c float16 v√† 32)
    # Model         |   VRAM    |   T·ªëc ƒë·ªô      |   ƒê·ªô ch√≠nh x√°c    
    # small         |   ~2GB    |   nhanh       |   Kh√°
    # medium        |   ~5GB    |   v·ª´a ph·∫£i    |   T·ªët (b·∫Øt bu·ªôc v·ªõi Ti·∫øng Vi·ªát)
    # large-v2      |   ~8-10GB |   ch·∫≠m        |   R·∫•t t·ªët
    # large-v3      |   ~10GB   |   ch·∫≠m nh·∫•t   |   T·ªët nh·∫•t
    

    if app.transcribe_file(MY_AUDIO, language="en"):
        duration = time.time() - start
        size_mb = os.path.getsize(MY_AUDIO) / 1048576 if os.path.exists(MY_AUDIO) else 0
        write_log(os.path.basename(MY_AUDIO), size_mb, duration, model_size, compute_type, batch_size)
        
    app.close()