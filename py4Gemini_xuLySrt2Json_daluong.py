import os
import re
import time
import concurrent.futures
from tqdm import tqdm  # Cáº§n cÃ i Ä‘áº·t: pip install tqdm
from google import genai
from google.api_core import exceptions
from google.genai import types

# --- Cáº¤U HÃŒNH ---
API_KEY = "AIzaSyARBZds9gF9-d4MYYe1accItEzgpKt3I-I"  # <-- DÃ¡n key má»›i cá»§a báº¡n vÃ o Ä‘Ã¢y
MODEL_NAME = "gemini-2.5-flash-lite"
MAX_WORKERS = 1  # Sá»‘ luá»“ng cháº¡y cÃ¹ng lÃºc. Flash Lite khÃ¡ nhanh, 5-8 lÃ  á»•n Ä‘á»‹nh.
BATCH_SIZE = 12 # Sá»‘ block SRT trong 1 láº§n gá»­i

# Khá»Ÿi táº¡o client
client = genai.Client(api_key=API_KEY)

def split_srt_blocks(content):
    """Chia ná»™i dung SRT thÃ nh list cÃ¡c block."""
    content = content.strip()
    blocks = re.split(r'\n\s*\n', content)
    # Lá»c bá» cÃ¡c block rá»—ng náº¿u cÃ³
    return [b for b in blocks if b.strip()]

def prompt_batch(concept, batch_content, batch_index, total_batches):
    """
    HÃ m xá»­ lÃ½ 1 batch. Tráº£ vá» tuple (index, response_text) Ä‘á»ƒ sau nÃ y sáº¯p xáº¿p láº¡i.
    """
    final_prompt = (
        f"{concept}\n\n"
        f"--- Báº®T Äáº¦U Dá»® LIá»†U PART {batch_index}/{total_batches} ---\n"
        f"{batch_content}\n"
        f"--- Káº¾T THÃšC Dá»® LIá»†U PART {batch_index}/{total_batches} ---"
    )

    # Retry mechanism
    for attempt in range(6): # Thá»­ tá»‘i Ä‘a 6 láº§n
        try:
            response = client.models.generate_content(
                model=MODEL_NAME,
                contents=final_prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json", # Ã©p tráº£ vá» dáº¡ng json 
                    temperature=0.1 # Giáº£m Ä‘á»™ sÃ¡ng táº¡o xuá»‘ng tháº¥p nháº¥t Ä‘á»ƒ á»•n Ä‘á»‹nh
                )
            )
            # Tráº£ vá» index vÃ  text Ä‘á»ƒ sort sau nÃ y
            return (batch_index, response.text)
            
        except exceptions.ResourceExhausted:
            wait_time = (attempt + 1) * 10 + 5 # 15s, 25s, 35s...
            # DÃ¹ng tqdm.write Ä‘á»ƒ khÃ´ng bá»‹ vá»¡ thanh process bar
            tqdm.write(f"âš ï¸ [Batch {batch_index}] Háº¿t Quota (429). Äá»£i {wait_time}s...")
            time.sleep(wait_time)
        except Exception as e:
            tqdm.write(f"âŒ [Batch {batch_index}] Lá»—i: {e}")
            time.sleep(5)
            
    return (batch_index, f"[FAILED BATCH {batch_index}]")

def process_srt_multithread(srt_path, concept_path, output_path):
    # 1. Äá»c dá»¯ liá»‡u
    print(f"ðŸ“– Äang Ä‘á»c file: {srt_path}")
    try:
        with open(srt_path, "r", encoding='utf-8') as f:
            contentOfSRT = f.read()
        with open(concept_path, "r", encoding='utf-8') as f:
            concept = f.read()
    except FileNotFoundError as e:
        print(f"âŒ Lá»—i file: {e}")
        return

    # 2. Chia batch
    all_blocks = split_srt_blocks(contentOfSRT)
    total_blocks = len(all_blocks)
    batches = [all_blocks[i:i + BATCH_SIZE] for i in range(0, total_blocks, BATCH_SIZE)]
    total_batches = len(batches)
    
    print(f"ðŸ“Š Tá»•ng block: {total_blocks} | Tá»•ng batch: {total_batches}")
    print(f"ðŸš€ Báº¯t Ä‘áº§u xá»­ lÃ½ song song vá»›i {MAX_WORKERS} luá»“ng...")

    # 3. Chuáº©n bá»‹ dá»¯ liá»‡u cho multithreading
    # Táº¡o list cÃ¡c arguments Ä‘á»ƒ truyá»n vÃ o hÃ m
    tasks = []
    for i, batch in enumerate(batches, 1):
        batch_str = "\n\n".join(batch)
        tasks.append((concept, batch_str, i, total_batches))

    results = []

    # 4. Thá»±c thi Äa luá»“ng
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # Submit cÃ¡c task vÃ o executor
        # future_to_index map giá»¯a future object vÃ  index batch (Ä‘á»ƒ debug náº¿u cáº§n)
        future_to_batch = {
            executor.submit(prompt_batch, concept, batch_str, idx, total): idx 
            for (concept, batch_str, idx, total) in tasks
        }

        # Sá»­ dá»¥ng tqdm Ä‘á»ƒ hiá»ƒn thá»‹ tiáº¿n trÃ¬nh hoÃ n thÃ nh
        for future in tqdm(concurrent.futures.as_completed(future_to_batch), total=total_batches, desc="Tiáº¿n Ä‘á»™"):
            try:
                # result á»Ÿ Ä‘Ã¢y lÃ  tuple (batch_index, text) tá»« hÃ m prompt_batch
                data = future.result()
                results.append(data)
            except Exception as exc:
                idx = future_to_batch[future]
                print(f"Batch {idx} generated an exception: {exc}")

    # 5. Sáº¯p xáº¿p káº¿t quáº£ (Quan trá»ng!)
    # VÃ¬ cháº¡y song song nÃªn káº¿t quáº£ tráº£ vá» lá»™n xá»™n, cáº§n sort láº¡i theo batch_index
    print("\nðŸ”„ Äang sáº¯p xáº¿p láº¡i thá»© tá»± cÃ¡c pháº§n...")
    results.sort(key=lambda x: x[0]) 

    # 6. LÆ°u file
    print(f"ðŸ’¾ Äang lÆ°u vÃ o file: {output_path}")
    with open(output_path, "w", encoding='utf-8') as f_out:
        # Chá»‰ láº¥y pháº§n text (x[1]) Ä‘á»ƒ ghi
        final_text = "\n\n--- PART BREAK ---\n\n".join([x[1] for x in results])
        f_out.write(final_text)

    print("âœ… HoÃ n táº¥t!")

# --- PHáº¦N THá»°C THI ---
if __name__ == "__main__":
    name_file = "50 2 Intro_Final"
    
    file_srt = name_file + ".srt"
    file_concept = "prompt4_SRT.txt"
    file_out = name_file + "_Response_MultiThread.txt"

    # Cháº¡y hÃ m chÃ­nh
    process_srt_multithread(file_srt, file_concept, file_out)